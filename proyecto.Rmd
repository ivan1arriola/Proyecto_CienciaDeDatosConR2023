---
title: "Proyecto final"
author: "Iván Arriola, Federico Miquelerena, Damián Rovetta"
date: "12-07-2023"
output: pdf_document
bibliography: [packages.bib, bibliografia.bib]
nocite: "@*"
header-includes:
  - \usepackage{float}
  - \floatplacement{figure}{H}
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE, fig.pos = "H", out.extra = "")
```

```{r Librerias , include = FALSE}
library(tidyverse)
library(DBI)
library(RPostgres)
library(sf)
library(paletteer)
library(geouy)
library(spdep)
library(xtable)
library(rpart)
library(rpart.plot)
source(here::here("app", "utils.R"))
library(randomForest)
library(modelr)
```

```{r Variables de Entorno, eval=FALSE, echo=FALSE}
usethis::edit_r_environ(
  scope = "project"
)
```

# Introducción

Esto es un análisis descriptivo de los datos del tráfico de Montevideo, Uruguay.
Hemos tomado los registros desde enero de 2021 hasta mayo de 2023 y nuestro interés es saber el comportamiento de la velocidad y el volumen de tráfico (variables explicativas) dependiendo de varias variables que iremos desarrollando a lo largo de la investigación.

# Datos

### Descripción general de los datos

Todos los datos fueron sacados de Catalogo de Datos Abiertos de **gub.uy**.
En particular, los datos elegidos son los siguientes:

- [Conteo vehicular en las principales avenidas de Montevideo](https://catalogodatos.gub.uy/dataset/intendencia-montevideo-conteo-de-vehiculos-del-centro-de-gestion-de-la-movilidad)
- [Velocidad promedio vehicular en las principales avenidas de Montevideo](https://catalogodatos.gub.uy/dataset/intendencia-montevideo-velocidad-promedio-vehicular-en-las-principales-avenidas-de-montevideo)
- [Ubicación de sensores de medición de conteo vehículos](https://catalogodatos.gub.uy/dataset/intendencia-montevideo-ubicacion-de-sensores-de-medicion-de-conteo-vehiculos)

Los tres dataset son mantenidos por la Intendencia de Montevideo.

### Descripcion de variables

Originalmente los datos vienen presentados de la siguiente forma:

#### Conteo vehicular en las principales avenidas de Montevideo

- `cod_detector`: Numérico - ID de la cámara que monitorea un carril específico para detectar vehículos.
- `id_carril`: Numérico - Número del carril monitoreado (1, 2, 3, ...).
- `fecha`: Fecha, AAAA-MM-DD - Día en que se realizó la medición.
- `hora`: hh:mm:ss - Hora en que se realizó la medición.
- `dsc_avenida`: Texto - Nombre de la avenida donde se mide el tráfico.
- `dsc_int_anterior`: Texto - Nombre de la vía desde donde vienen los vehículos.
- `dsc_int_siguiente`: Texto - Nombre de la vía hacia donde se dirigen los vehículos.
- `latitud`: Float - Latitud del lugar de medición.
- `longitud`: Float - Longitud del lugar de medición.
- `volumen`: Numérico - Cantidad de vehículos detectados en el carril en los últimos 5 minutos.
- `volumen_hora`: Numérico - Cantidad de vehículos detectados en el carril en la última hora.

#### Velocidad promedio vehicular en las principales avenidas de Montevideo

- `cod_detector`: Numérico - ID de la cámara que monitorea un carril específico para detectar vehículos.
- `id_carril`: Numérico - Número del carril monitoreado (1, 2, 3, ...).
- `fecha`: AAAA-MM-DD - Día en que se realizó la medición.
- `hora`: hh:mm:ss - Hora en que se realizó la medición.
- `dsc_avenida`: Texto - Nombre de la avenida donde se mide el tráfico.
- `dsc_int_anterior`: Texto - Nombre de la vía desde donde vienen los vehículos.
- `dsc_int_siguiente`: Texto - Nombre de la vía hacia donde se dirigen los vehículos.
- `latitud`: Float - Latitud del lugar de medición.
- `longitud`: Float - Longitud del lugar de medición.
- `velocidad_promedio`: Numérico - Promedio de las velocidades de los vehiculos que circularon por el carril durante los últimos 5 minutos.

#### Ubicación de sensores de medición de conteo vehículos

- `dsc_avenida`: Texto - Nombre de la avenida donde se encuentra el sensor o cámara y donde se mide el tránsito.
- `dsc_int_anterior`: Texto - Nombre de la vía que forma el cruce desde donde vienen los vehículos.
- `dsc_int_siguiente`: Texto - Nombre de la vía que forma el cruce donde está el sensor. En general, el sensor se encuentra un poco antes de esta vía. El sentido de circulación será desde el cruce con `dsc_int_anterior` hacia el cruce con `dsc_int_siguiente`.
- `latitud`: Float - Coordenada que indica la latitud de la ubicación del sensor.
- `longitud`: Float - Coordenada que indica la longitud de la ubicación del sensor.

Sobre estos datos en particular, son _100 sensores_ que se van cambiando de ubicación mes a mes.

## Base de datos

Debido a que los datos están estrechamente relacionados y a su vez son sumamente masivos, hemos decidido utilizar una base de datos quedando de la siguiente manera.

```{r Coneccion a Base de Datos, include = FALSE}
con <- DBI::dbConnect(
  RPostgres::Postgres(),
  host = Sys.getenv("DB_HOST"),
  port = Sys.getenv("DB_PORT"),
  user = Sys.getenv("DB_USER"),
  password = Sys.getenv("DB_PASS"),
  dbname = Sys.getenv("DB_NAME")
)
```

![Diagrama de la base de datos](app/media/fct_registros.png "Diagrama de la base de datos"){width="300" height="600"}

Nuestra tabla principal será `fct_registros`.

### Tabla: fct_registros

- Cantidad de datos: 85386695.
- Variables de la tabla:
  - `id_registros`: _Numérico_ (_Primary Key_).
  - `id_carril`: _Numérico_.
  - `id_fecha`: _Numérico_ (_Foreign Key_, vinculado con `d_sensores`). La fecha de la que fue tomada el registro, tiene el formato _YYYY-MM-DD_
  - `id_hora`: _Numérico_. Hora en la que fue tomado el registro con formato _HHMM_.
  - `id_detector`: _Numérico_ (_Foreign Key_, cinculado con `d_date`).
  - `volume`: _Numérico_. Cantidad de vehiculos que pasaron en los últimos 5 minutos.
  - `volumen_hora`: _Numérico_. Cantidad de vehiculos que pasaron en la ultima hora.
  - `velocidad`: _Numérico_. Velocidad promedio de los vehiculos registrados en los utimos 5 minutos. Unidad en km/h

### Tabla: d_sensores

- Cantidad de datos: 273
- Variables de la tabla:
  - `id_detector`: _Numérico_ (_Primary Key_).
  - `dsc_avenida`: _Texto_. Calle donde se encuentra el sensor.
  - `dsc_int_anterior`: _Texto_. Cruce previo de la calle en `dsc_avenida`.
  - `dsc_int_siguiente`: _Texto_. Cruce posterior de la calle en `dsc_avenida`. Estas dos juntas nos dirá que cada sensor se encuentra en _Avenida_ entre _Anterior_ y _Siguiente_.
  - `latitud`: _Numérico continuo_.
  - `longitud`: _Numérico continuo_. Junto a `latitud` nos indica las coordenadas geograficas del sensor.
  - `barrio`: _Texto_. Esta variable fue creada a partir del paquete `geouy`

### Tabla: d_date

- Cantidad de datos: 3652
- Variables de la tabla:
  - `id_fecha`: _Numérico_ (_Primary Key_)
  - `date_actual`: _Fecha_. Secuencia de fechas desde el 01-01-2021 con formato _YYYY-MM-DD_
  - `epoch`
  - `day_suffix`: _Texto_. Fecha del dia abreviado.
  - `day_name`: _Texto_. Nombre del día
  - `day_of_week`: _Numérico_. Dia de la semana que indica 1 como lunes, 2 como martes, etc.
  - `day_of_month`: _Numérico_. Fecha del mes, va desde 1 hasta 31.
  - `day_of_quarter`: _Numérico_. Dia del cuatrimestre.
  - `day_of_year`: _Numérico_. Dia del año, del 1 al 366.
  - `week_of_month`: _Numérico_. Semana de cada mes, valores del 1 al 5.
  - `week_of_year`: _Numérico_. Semana del año, valores del 1 al 53.
  - `week_of_year_iso`: _Texto_. Variable que combina el año, la semana del año y el día de la semana.
  - `month_actual`: _Numérico_. Mes del año tomado como numero, enero como 1, febrero como 2 y así sucesivamente.
  - `month_name`: _Texto_. Mes del año traducido en texto, de enero a diciembre
  - `month_name_abbreviated`: _Texto_. Mes del año en formato abreviado.
  - `quarter_actual`: _Numérico_. Indica el cuatrimestre correspondiente con numeros del 1 al 4.
  - `quarter_name`: _Texto_. Indica el cuatrimestre en formato de texto, primero, segundo, tercero y cuarto.
  - `year_actual`: _Numérico_. Indica el año.
  - `first_day_of_week`: _Fecha_. Indica el primer día de la semana que corresponde tal fecha.
  - `last_day_of_week`: _Fecha_. Indica el ultimo día del rango de la semana correspondiente.
  - `first_day_of_month`: _Fecha_. Limite inferior que indica a que mes corresponde cada fecha.
  - `last_day_of_month`: _Fecha_. Limite superior que indica a que mes corresponde cada fecha.
  - `first_day_of_quarter`: _Fecha_. Limite inferior que indica a que cuatrimestre corresponde cada fecha.
  - `last_day_of_quarter`: _Fecha_. Limite superior que indica a que cuatrimestre corresponde cada fecha.
  - `first_day_of_year`: _Fecha_. Limite inferior que indica a que año corresponde cada fecha.
  - `last_day_of_year`: _Fecha_. Limite superior que indica a que año corresponde cada fecha.
  - `mmyyyy`: _Numérico_. Secuencia de caracteres que indica el mes y el año en formato MMYYY
  - `mmddyyyy`: _Numérico_. Secuencia de caracteres que indica el mes, la fecha y el año en formato MMDDYYY.
  - `weekend_indr`: _Lógico_. `TRUE` si la fecha tiene como dia de la semana sabado o domingo, `FALSE` en caso contrario.
  - `feriado`: _Lógico_. `TRUE` si la fecha correspondiente coincide con dias feriados en Uruguay, `FALSE` en caso contrario.

# Análisis exploratorio

En nuestro proyecto tenemos datos que tienen una dimension geo-espacial, por lo que es importante tener en cuenta
que la información que tenemos no es homogenea. Tambien es importante tener en cuenta que la información que tenemos
es de un periodo de tiempo acotado.

Dicho esto, para empezar, me parecio adecuado comprobar la integridad de los datos, es decir, ver si tenemos datos
faltantes o datos que no tienen sentido.

## Datos faltantes y nulos

```{r Cantidad de datos faltantes y nulos, echo = FALSE}
# Cantidad de datos faltantes y nulos
tabla_datos_null <- load_data('tabla_datos_null.csv',con,
"
SELECT 'velocidad' AS atributo,
       COUNT(*) AS cant_total,
       SUM(CASE WHEN velocidad IS NULL THEN 1 ELSE 0 END) AS cant_null,
       SUM(CASE WHEN velocidad = 0 THEN 1 ELSE 0 END) AS cant_0
FROM fct_registros
UNION ALL
SELECT 'volumem_hora' AS atributo,
       COUNT(*) AS cant_total,
       SUM(CASE WHEN volumen_hora IS NULL THEN 1 ELSE 0 END) AS cant_null,
       SUM(CASE WHEN volumen_hora = 0 THEN 1 ELSE 0 END) AS cant_0
FROM fct_registros
UNION ALL
SELECT 'volume' AS atributo,
       COUNT(*) AS cant_total,
       SUM(CASE WHEN volume IS NULL THEN 1 ELSE 0 END) AS cant_null,
       SUM(CASE WHEN volume = 0 THEN 1 ELSE 0 END) AS cant_0
FROM fct_registros
UNION ALL
SELECT 'id_fecha' AS atributo,
       COUNT(*) AS cant_total,
       SUM(CASE WHEN id_fecha IS NULL THEN 1 ELSE 0 END) AS cant_null,
       SUM(CASE WHEN id_fecha = 0 THEN 1 ELSE 0 END) AS cant_0
FROM fct_registros
UNION ALL
SELECT 'id_detector' AS atributo,
       COUNT(*) AS cant_total,
       SUM(CASE WHEN id_detector IS NULL THEN 1 ELSE 0 END) AS cant_null,
       0 AS cant_0
FROM fct_registros;
") %>%
  mutate(
    porc_null = round(cant_null / cant_total * 100, 6),
    porc_0 = round(cant_0 / cant_total * 100, 6)
  )
print(tabla_datos_null)
```

En `r tabla_datos_null[5,3]` datos se perdio la informacion de la ubicacion del sensor, por lo que no sabemos de que calle se trata.
En el `r tabla_datos_null[1,6]`% de los datos se detecto velocidad 0 y en el mismo porcentaje se detecto volumen 0, se tiene que averiguar
si son en los mismos registros o no.

```{r, echo = FALSE}
# Cantidad de datos que tienen velocidad 0 y volumen 0
datos_0 <- load_data('datos_0.csv',con,
"
SELECT COUNT(*) AS cant_total,
       SUM(CASE WHEN velocidad = 0 AND volumen_hora = 0 THEN 1 ELSE 0 END) AS cant_0
FROM fct_registros;
") %>%
  mutate(
    porc_0 = round(cant_0 / cant_total * 100, 6)
  )
print(datos_0)
```

Las cantidades coinciden, por lo que se puede asumir que son registros donde el sensor no detecto ningun vehiculo.
Indicando que el `r tabla_datos_null[1,6]`%
de los datos son registros donde no se detecto ningun vehiculo.

Sobre los datos faltantes de la ubicacion del sensor, son datos que no se pueden recuperar, por lo que se tendran
que descartar.

Se quiso averiguar en que fecha se perdio la informacion de la ubicacion del sensor, para ver si se podia recuperar
la informacion de otra forma, pero no se pudo.

```{r, echo = FALSE}
# Fecha en la que se perdio la informacion de la ubicacion del sensor
load_data('fecha_null.csv',con,
"
SELECT id_fecha,
       COUNT(*) AS cant_total,
       SUM(CASE WHEN id_detector IS NULL THEN 1 ELSE 0 END) AS cant_null
FROM fct_registros
GROUP BY id_fecha
HAVING SUM(CASE WHEN id_detector IS NULL THEN 1 ELSE 0 END) > 0
ORDER BY id_fecha;
") %>%
  mutate(
    porc_null = round(cant_null / cant_total * 100, 6)
  )
```

```{r, echo = FALSE}
datos_null <- load_data('datos_null.csv',
  con,
  "SELECT *
  FROM fct_registros
  WHERE id_detector IS NULL
  "
)

datos_null$fecha <- as.Date(as.character(datos_null$id_fecha), format = "%Y%m%d")
datos_null$hora <- datos_null$id_hora

summary(datos_null)

```

Se puede ver que los datos faltantes de la ubicacion del sensor van desde el 24/07/2021 hasta el 31/07/2021.
Tambien se puede ver que todos los datos faltantes son del carril 2.
Quiza se podrian recuperar los datos de la ubicacion del sensor revisando los datos originales pero es irrelevante
ya que son pocos datos y no afectan al analisis.

## Ubicacion de los sensores

Los datos que tenemos son de 100 sensores ubicados todos en Montevideo y estos van cambiando de ubicacion cada mes.
Por lo que el primer paso es ver cuantas ubicaciones distintas tenemos y cuantos sensores hay en cada ubicacion.

```{r Cargar mapas y sensores,  message=FALSE, results='hide'}
d_sensores <- load_data("d_sensores.csv",
  con,
  "SELECT * FROM d_sensores"
  )
mvd_map <- load_geouy("Barrios")
mvd_map_fixed <- st_make_valid(st_transform(mvd_map, crs = 4326))
puntos_sensores <- d_sensores %>%
  select(barrio, latitud, longitud) %>%
  mutate(transformarCoord(latitud, longitud, mvd_map))
```

Para mostrarlo, hemos decidido utilizar un mapa de Montevideo con los barrios y mostramos la cantidad de sensores ubicados en el.
En el mapa se puede ver que los sensores estan ubicados en 42 de los 62 barrios de Montevideo.
Los barrios que tienen sensores son 42 sobre 62 siendo los barrios de Buceo, Centro, Pocitos y Unión con mas de 20 sensores.

```{r Cantidad de sensores por barrio, echo = FALSE, fig.cap = 'Mapa de Montevideo con cantidad de sensores por barrio.'}
cant_sensores <- d_sensores %>%
  group_by(barrio) %>%
  summarise(
    cant_de_sensores = n()
    ) %>%
  arrange(desc(cant_de_sensores))

mvd_map_sensores <- mvd_map_fixed %>%
  left_join(cant_sensores, by = c("nombbarr" = "barrio")) %>%
  mutate(cant_de_sensores = ifelse(is.na(cant_de_sensores), 0, cant_de_sensores))

ggplot() +
  geom_sf(
    data = mvd_map_sensores,
    aes(
      fill = ifelse(cant_de_sensores == 0, NA, cant_de_sensores)
    )
  ) +
  scale_fill_viridis_c(option = "plasma", name = "Cantidad de sensores por barrio") +
  theme_void() +
  theme(legend.position = "bottom")
```

Ahora quiero mostrar la cantidad de datos que tenemos por ubicacion, para ver si hay alguna ubicacion en particular que
tenga mas o menos datos que las demas.

```{r Cantidad de datos por ubicacion, echo = FALSE}
cant_datos_por_ubicacion <- load_data("cant_datos_por_ubicacion.csv",
  con,
  "
    SELECT
      id_detector,
      d_date.mmyyyy,
      COUNT(*) AS cant_datos
    FROM fct_registros
    LEFT JOIN d_date on d_date.id_fecha = fct_registros.id_fecha
    GROUP BY id_detector, d_date.mmyyyy
  "
) %>% inner_join(
  d_sensores %>% select(barrio, id_detector), by = c("id_detector" = "id_detector")
) %>% inner_join(
  cant_sensores, by = c("barrio" = "barrio")
)
```

```{r PLOT Cantidad de datos por ubicacion, echo = FALSE, fig.cap = 'Cantidad de datos por ubicacion'}
cant_datos_por_barrio <- cant_datos_por_ubicacion %>%
  group_by(barrio) %>%
  summarise(
    cant_datos = sum(cant_datos)
  ) %>%
  arrange(desc(cant_datos))

cant_datos_por_barrio %>%
  ggplot(aes(x = fct_reorder(barrio, cant_datos), y = cant_datos, fill = barrio)) +
  geom_bar(stat = "identity", position = "stack") +
  theme(axis.text.x = element_text(size= 5, angle = 45, hjust = 1)) +
  scale_x_discrete(name = "Ubicacion") +
  scale_y_continuous(labels = scales::comma, name = "Cantidad de datos") +
  theme(
    legend.position = 'none'
  )

```

Se puede observar que la cantidad de datos por ubicacion no es para nada homogenea.
Los barrios con mayor cantidad de datos aportados al dataset son Union, Pocitos, Tres Cruces, Buceo y Centro.
Por otro lado Maroñas, Carrasco, Las Canteras y Cerrito son los que menos datos aportan.

Ahora me interesaria saber cuales son los barrios mejores representados en el dataset, es decir, cuales son los barrios
que tienen mas datos por metro cuadrado.

primero calculo el area de cada barrio y luego calculo la cantidad de datos por metro cuadrado.

```{r Mapa Montevideo con Area, echo = FALSE}
mvd_map_con_area <- mvd_map_fixed %>%
  mutate(
    area = as.numeric(st_area(mvd_map_fixed))
  ) %>% arrange(area)

```

```{r Cantidad de datos por ubicacion ponderado por area, echo = FALSE}
cant_datos_por_barrio_area <- cant_datos_por_ubicacion %>%
  group_by(barrio) %>%
  summarise(
    cant_datos = sum(cant_datos)
  ) %>%
  inner_join(
    mvd_map_con_area %>% select(nombbarr, area), by = c("barrio" = "nombbarr")
  ) %>%
  mutate(
    cant_datos_por_area = cant_datos / area
  ) %>%
  arrange(desc(cant_datos_por_area))
```

```{r PLOT Cantidad de datos por ubicacion ponderado por area, echo = FALSE, fig.cap = 'Cantidad de datos por ubicacion ponderado por area'}
cant_datos_por_barrio_area %>%
  ggplot(aes(x = fct_reorder(barrio, cant_datos_por_area), y = cant_datos_por_area, fill = barrio)) +
  geom_bar(stat = "identity", position = "stack") +
  theme(axis.text.x = element_text(size= 5, angle = 45, hjust = 1)) +
  scale_x_discrete(name = "Ubicacion") +
  scale_y_continuous(labels = scales::comma, name = "Cantidad de datos por metro cuadrado") +
  theme(
    legend.position = 'none'
  )

```

Se puede observar que los barrios con mayor cantidad de datos por metro cuadrado son Pocitos,
La Blanqueada, Jancito Vera, Centro y Tres Cruces.
Por otro lado Maroñas, Carrasco, Las Canteras, Peñarol y Cerrito son los que menos datos aportan por metro cuadrado.

## Principales variables

Las variables que se van a analizar son las siguientes: - `volume`: _Numérico_. Cantidad de vehiculos que pasaron en los últimos 5 minutos. - `volumen_hora`: _Numérico_. Cantidad de vehiculos que pasaron en la ultima hora. - `velocidad`: _Numérico_. Velocidad promedio de los vehiculos registrados en los utimos 5 minutos. Unidad en km/h

### Velocidad

Resumen de la variable velocidad

```{r Resumen de la variable velocidad, echo = FALSE}
(
    resumen_velocidad <- load_data("resumen_velocidad.csv",
    con,
      "
        SELECT
          MIN(velocidad) AS minimo,
          PERCENTILE_CONT(0.25) WITHIN GROUP (ORDER BY velocidad) AS primer_cuartil,
          PERCENTILE_CONT(0.5) WITHIN GROUP (ORDER BY velocidad) AS mediana,
          PERCENTILE_CONT(0.75) WITHIN GROUP (ORDER BY velocidad) AS tercer_cuartil,
          MAX(velocidad) AS maximo,
          AVG(velocidad) AS promedio,
          STDDEV(velocidad) AS desvio
        FROM fct_registros
      "
    )
)
```







Ahora veamos la distribucion de la velocidad registrada
Para mejor visualizacion, voy a dejar de lado los datos donde la velocidad es 0

```{r Datos de velocidad y Volumen, echo = FALSE}
  velocidad_volumen <- load_data('velocidad_volumen.csv',
  con,
  "
  SELECT
    fct_registros.velocidad,
    fct_registros.volume AS volumen
  FROM
    fct_registros TABLESAMPLE SYSTEM (1)
  WHERE
    fct_registros.velocidad > 0
  "
)
```

```{r, Distribucion de velocidad Barras, fig.cap= "Distribucion de velocidad promedio"}
velocidad_media <- mean(velocidad_volumen$velocidad)
velocidad_desvio <- sd(velocidad_volumen$velocidad)

velocidad_volumen %>% ggplot() +
  geom_density(aes(x = velocidad), fill = "blue", alpha = 0.5, kernel = "epanechnikov") +
  geom_histogram(aes(x = velocidad, y = after_stat(density) ), fill = "red", alpha = 0.5, bins = 144)+
  scale_x_continuous(name = "Velocidad promedio (km/h)") +
  scale_y_continuous(name = "Densidad") +
  theme(
    legend.position = 'none'
  ) +
  geom_vline(xintercept = velocidad_media, color = "black", linetype = "dashed", size = 1) +
  annotate("text", x = velocidad_media + 5, y = 0.02, label = paste("Velocidad promedio:", round(velocidad_media, 2), "km/h"), size = 3) +
  geom_vline(xintercept = velocidad_media + velocidad_desvio, color = "black", linetype = "dashed", size = 1) +
  geom_vline(xintercept = velocidad_media - velocidad_desvio, color = "black", linetype = "dashed", size = 1)
```

Se puede observar que la distribucion de la velocidad es normal, con una media de 31.31 km/h y un desvio de 17.08 km/h.
El 68% de los datos se encuentran entre 14.23 km/h y 48.39 km/h.

### Volumen

Resumen de la variable volumen

minimo, maximo, promedio, desvio, cuartiles

```{r Resumen de la variable volumen, echo = FALSE}
(
    resumen_volumen <- load_data("resumen_volumen.csv",
    con,
      "
        SELECT
          MIN(volume) AS minimo,
          PERCENTILE_CONT(0.25) WITHIN GROUP (ORDER BY volume) AS cuartil_1,
          PERCENTILE_CONT(0.5) WITHIN GROUP (ORDER BY volume) AS mediana,
          PERCENTILE_CONT(0.75) WITHIN GROUP (ORDER BY volume) AS cuartil_3,
          MAX(volume) AS maximo,
          AVG(volume) AS promedio,
          STDDEV(volume) AS desvio
        FROM fct_registros
      "
    )
)
```




Se ve que la cantidad minima de vehiculos registrados en 5 minutos es 0 y la maxima es 659.
El promedio de volumen es 17.28 vehiculos y el desvio estandar es 19.18 vehiculos.

Ahora veamos la distribucion del volumen registrado
Para mejor visualizacion, voy a dejar de lado los datos donde el volumen es 0

```{r, Distribucion de volumen Barras, fig.cap= "Distribucion de volumen"}
volumen_media <- mean(velocidad_volumen$volumen)
volumen_desvio <- sd(velocidad_volumen$volumen)

velocidad_volumen %>% ggplot() +
  geom_density(aes(x = volumen), fill = "blue", alpha = 0.5, kernel = "epanechnikov") +
  geom_histogram(aes(x = volumen, y = after_stat(density) ), fill = "red", alpha = 0.5, bins = 144)+
  scale_x_continuous(name = "Volumen de vehiculos") +
  scale_y_continuous(name = "Densidad") +
  theme(
    legend.position = 'none'
  ) +
  geom_vline(xintercept = volumen_media, color = "black", linetype = "dashed", size = 1) +
  annotate("text", x = volumen_media + 5, y = 0.02, label = paste("Volumen promedio:", round(volumen_media, 2), "vehiculos"), size = 3) +
  geom_vline(xintercept = volumen_media + volumen_desvio, color = "black", linetype = "dashed", size = 1) +
  geom_vline(xintercept = volumen_media - volumen_desvio, color = "black", linetype = "dashed", size = 1)
```

Se puede observar que la mayoria de los valores son menores a 100, en particular
el 75% de los datos son menores a `r round(resumen_volumen$cuartil_3, 2)` vehiculos.


# Preguntas de Investigacion

Las preguntas que dirigiran este analisis son las siguientes:
1.  ¿Existe alguna correlación entre el volumen y la velocidad?
2.  ¿Cuáles son las calles con los mayores promedios de velocidad en Montevideo? ¿Con que frecuencia se cometen excesos de velocidad?
3. ¿Cómo va variando el volumen y velocidad medidos a través del TIEMPO?


##   ¿Existe alguna correlación entre el volumen y la velocidad?

Haremos un grafico de puntos para visualizarlo.
Para los datos usaremos una muestra aleatoria de toda la base de datos 


```{r Muestra y Plot, fig.cap="Grafico de puntos de velocidad y volumen"}

velocidad_volumen_muestra <- velocidad_volumen %>% sample_n(nrow(velocidad_volumen)*0.3)

velocidad_volumen_muestra %>% ggplot() + geom_point(
  aes(
    x = velocidad,
    y= volumen
  )
)

```
Definitivamente **no hay una relacion lineal** entre velocidad y volumen

```{r Correlacion de velocidad y volumen}
cor(velocidad_volumen)
```
 La correlacion dio `r round(cor(velocidad_volumen$velocidad, velocidad_volumen$volumen), 2)`, lo que indica que no hay una correlacion lineal entre las variables.